{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Scripts to practise making ATom data comparable with UKCA data. Later on, this will be done properly with the SSP AMIP suites. Using my outputs from the test suite for now.\n",
        "\n",
        "See also https://github.com/theabro/ukca/blob/master/Tutorials/UMvn13.0/notebooks/iris_toz01.ipynb"
      ],
      "metadata": {
        "id": "N5QoXjXlfcEF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0_W8BdmTOLS",
        "outputId": "ca5093d6-179e-4c90-8421-3c1cedb88c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.1/518.1 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cartopy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q scitools-iris"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import iris\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooMwQtW1TRRh",
        "outputId": "804c0106-ce72-4cbd-edee-414ee224a866"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This step takes several minutes. Better to load individual chunks than the whole thing. See stash codes text file.\n",
        "p_file = '/content/drive/MyDrive/Documents/AI4ER/PhD/Photolysis_data/atmosa.pb1988sep'\n",
        "#UKCA_data = iris.load(p_file)\n",
        "UKCA_O3 = iris.load_cube(p_file,iris.AttributeConstraint(STASH='m01s50i567')) # O3 --> O(1D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc81LuLWWfsK",
        "outputId": "2ce8da05-eec5-4425-a41d-634d57721520"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/iris/fileformats/pp.py:1574: UserWarning: has_year_zero kwarg ignored for idealized calendars (always True)\n",
            "  self._t1 = cftime.datetime(\n",
            "/usr/local/lib/python3.10/dist-packages/iris/fileformats/pp.py:1609: UserWarning: has_year_zero kwarg ignored for idealized calendars (always True)\n",
            "  self._t2 = cftime.datetime(\n",
            "/usr/local/lib/python3.10/dist-packages/cf_units/__init__.py:402: UserWarning: has_year_zero kwarg ignored for idealized calendars (always True)\n",
            "  dates = np.array([dt and dt.replace(microsecond=0) for dt in dates])\n",
            "/usr/local/lib/python3.10/dist-packages/iris/fileformats/rules.py:353: UserWarning: Unable to create instance of HybridHeightFactory. The source data contains no field(s) for 'orography'.\n",
            "  warnings.warn(msg.format(factory=factory_name))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "print(type(UKCA_data))\n",
        "print(UKCA_data.shape)\n",
        "print(UKCA_data)\n",
        "'''\n",
        "print(type(UKCA_O3)) # iris cube\n",
        "print(UKCA_O3.shape) # 47 t, 85 z, 144 y, 192 x\n",
        "print(UKCA_O3)"
      ],
      "metadata": {
        "id": "Q93B3VihZU1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a0e9ff-d420-4e97-fcb0-b55c549ef29f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'iris.cube.Cube'>\n",
            "(47, 85, 144, 192)\n",
            "m01s50i567 / (unknown)              (time: 47; model_level_number: 85; latitude: 144; longitude: 192)\n",
            "    Dimension coordinates:\n",
            "        time                             x                       -             -               -\n",
            "        model_level_number               -                       x             -               -\n",
            "        latitude                         -                       -             x               -\n",
            "        longitude                        -                       -             -               x\n",
            "    Auxiliary coordinates:\n",
            "        forecast_period                  x                       -             -               -\n",
            "        level_height                     -                       x             -               -\n",
            "        sigma                            -                       x             -               -\n",
            "    Scalar coordinates:\n",
            "        forecast_reference_time     1988-09-01 00:00:00\n",
            "    Attributes:\n",
            "        STASH                       m01s50i567\n",
            "        source                      'Data from Met Office Unified Model'\n",
            "        um_version                  '13.0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The UKCA test suite simulates 1st and 2nd September 1988.\n",
        "# The most similar time of year in the ATom data is 23rd August 2016.\n",
        "\n",
        "# Open the .csv of all the ATom data which I have already pre-processed in the script, ATom_J_data.\n",
        "ATom_file = '/content/drive/MyDrive/Documents/AI4ER/PhD/Photolysis_data/ATom_MER10_Dataset.20210613/photolysis_data.csv'\n",
        "ATom_data = pd.read_csv(ATom_file, index_col=0) # shape = 138454, 49. 138454 time steps, 49 = chemicals + spatial dimensions."
      ],
      "metadata": {
        "id": "QPbp04JfJ7Nf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick out just the 22nd and 23rd August indices separately.\n",
        "A_day1 = ATom_data[ATom_data.index.str.contains('2016-08-22')] # shape = 1994, 49. 1994 time steps for 22/8/16, 49 = chemicals + spatial dimensions.\n",
        "A_day1_O3 = A_day1[['G_LAT', 'G_LONG', 'G_ALT', 'jO3_O2_O1D_CAFS']] # shape = 1994, 4.\n",
        "\n",
        "A_day2 = ATom_data[ATom_data.index.str.contains('2016-08-23')] # shape = 1765, 49. 1765 time steps for 23/8/16, 49 = chemicals + spatial dimensions.\n",
        "A_day2_O3 = A_day2[['G_LAT', 'G_LONG', 'G_ALT', 'jO3_O2_O1D_CAFS']] # shape = 1765, 4.\n",
        "\n",
        "# Check what the time of day range is for both.\n",
        "print(A_day1_O3.index[0]) # 12:53:40\n",
        "print(A_day1_O3.index[-1], '\\n') # 18:51:40\n",
        "print(A_day2_O3.index[0]) # 15:05:40\n",
        "print(A_day2_O3.index[-1]) # 20:00:20\n",
        "\n",
        "# Trim so that all arrays are over the same times. # 15:05:40 to 18:51:40\n",
        "A_day1_O3 = A_day1_O3.loc['2016-08-22 15:05:40':'2016-08-22 18:51:40'] # shape = 1205, 4. type = pandas dataframe.\n",
        "A_day2_O3 = A_day2_O3.loc['2016-08-23 15:05:40':'2016-08-23 18:51:40'] # shape = 1353, 4. type = pandas dataframe."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuUo9RMqPCAw",
        "outputId": "0265993b-3ec3-4f88-b8e4-b2a8f8088fde"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2016-08-22 12:53:40\n",
            "2016-08-22 18:51:40 \n",
            "\n",
            "2016-08-23 15:05:40\n",
            "2016-08-23 20:00:20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape = 47 t, 85 z, 144 y, 192 x. type = iris cube.\n",
        "\n",
        "# Check what time zones ATom and UM are using. ATom: UTC. UM: UTC.\n",
        "# Get the UM data for the same time of day for both 1st and 2nd sep separately.\n",
        "U_day1_O3 = UKCA_O3[13:18]\n",
        "U_day2_O3 = UKCA_O3[37:42] # shape = 5 t, 85 z, 144 y, 192 x. type = iris cube.\n",
        "\n",
        "times = ['2016-08-22 15:05:40', '2016-08-22 16:00:00', '2016-08-22 17:00:00', '2016-08-22 18:00:00', '2016-08-22 18:51:40']\n",
        "U_day, A_day = [], []\n",
        "\n",
        "for iTime in range(len(times)):\n",
        "\n",
        "  t = U_day1_O3[iTime]\n",
        "\n",
        "  # Check what units of altitude they're using. ATom: m. UM: m.\n",
        "  # Find out what the altitudes are for ATom and select the right altitudes of UKCA data.\n",
        "  Talt = A_day1_O3.loc[times[iTime]]['G_ALT']\n",
        "  Ualts = t.coord('level_height').points\n",
        "  diffs = np.absolute(Ualts-Talt)\n",
        "  iAlt = diffs.argmin()\n",
        "  t = U_day1_O3[iTime,iAlt]\n",
        "\n",
        "  # Check what units of latitude they're using. ATom: degrees +N. UM: degrees.\n",
        "  # Find out what the latitudes are for ATom and select the right latitudes of UKCA data.\n",
        "  Tlat = A_day1_O3.loc[times[iTime]]['G_LAT']\n",
        "  Ulats = t.coord('latitude').points\n",
        "  diffs = np.absolute(Ulats-Tlat)\n",
        "  iLat = diffs.argmin()\n",
        "  t = U_day1_O3[iTime,iAlt,iLat]\n",
        "\n",
        "  # Check what units of longitude they're using. ATom: degrees +E in half circles (-180 to 180). UM: degrees in a full circle (0 to 360).\n",
        "  # Find out what the longtitudes are for ATom and select the right longitudes of UKCA data.\n",
        "  Tlong = A_day1_O3.loc[times[iTime]]['G_LONG']\n",
        "  Ulongs = t.coord('longitude').points\n",
        "  if Tlong < 0:\n",
        "    Tlong = Tlong + 360\n",
        "  diffs = np.absolute(Ulongs-Tlong)\n",
        "  iLong = diffs.argmin()\n",
        "  t = U_day1_O3[iTime,iAlt,iLat,iLong]\n",
        "\n",
        "  U_day.append(t)\n",
        "  A_day.append(A_day1_O3.loc[times[iTime]])\n",
        "\n",
        "print(U_day[0])\n",
        "print(A_day[0])\n",
        "\n",
        "# Used Monsoon to check if sigma is the J rate. sigma is not J rate.\n",
        "# compare the 2 ATom days with each other for O3.\n",
        "# compare the 2 UM days with each other for O3.\n",
        "# compare the ATom days with the UM days.\n",
        "# Now put all the above into functions to work with different chemicals and times etc and try with NO2."
      ],
      "metadata": {
        "id": "GWiIbPxL-SCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1298b87d-0a29-4297-fadd-d071a6ee1beb"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m01s50i567 / (unknown)              (scalar cube)\n",
            "    Scalar coordinates:\n",
            "        forecast_period             15.0 hours\n",
            "        forecast_reference_time     1988-09-01 00:00:00\n",
            "        latitude                    59.375 degrees\n",
            "        level_height                2659.99935 m, bound=(2529.9995000000004, 2796.6666) m\n",
            "        longitude                   285.9375 degrees\n",
            "        model_level_number          19\n",
            "        sigma                       0.7220069222008947, bound=(0.734543106256622, 0.7089441261204913)\n",
            "        time                        1988-09-01 15:00:00\n",
            "    Attributes:\n",
            "        STASH                       m01s50i567\n",
            "        source                      'Data from Met Office Unified Model'\n",
            "        um_version                  '13.0'\n",
            "G_LAT                58.951297\n",
            "G_LONG              -74.854346\n",
            "G_ALT              2609.580000\n",
            "jO3_O2_O1D_CAFS       0.000028\n",
            "Name: 2016-08-22 15:05:40, dtype: float64\n"
          ]
        }
      ]
    }
  ]
}